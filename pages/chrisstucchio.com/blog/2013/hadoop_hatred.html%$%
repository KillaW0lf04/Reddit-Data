<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">
<head>
    <title>Don't use Hadoop - your data isn't that big - Chris Stucchio</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <!-- Open Graph tags -->
            <meta property="og:type" content="article"/>
            <meta property="og:title" content="Don't use Hadoop - your data isn't that big"/>
            <meta property="og:url" content="http://chrisstucchio.com/blog/2013/hadoop_hatred.html"/>
            <meta property="og:description" content=""So, how much experience do you have with Big Data and Hadoop?" they asked me. I told them that I use Hadoop all the time, but rarely for jobs larger than a few TB. I'm basically a big data neophite - I know the concepts, I've written code, but ..."/>

    <!-- Bootstrap -->
        <link rel="stylesheet" href="http://chrisstucchio.com/theme/css/bootstrap.css" type="text/css"/>
    <link href="http://chrisstucchio.com/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="http://chrisstucchio.com/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="http://chrisstucchio.com/theme/css/style.css" type="text/css"/>

        <link href="http://chrisstucchio.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Chris Stucchio ATOM Feed"/>
        <link href="http://chrisstucchio.com/blog/atom.xml" type="application/atom+xml" rel="alternate"
              title="Chris Stucchio ATOM Feed"/>



</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="http://chrisstucchio.com/" class="navbar-brand myname">
Chris Stucchio            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="http://chrisstucchio.com/publications.html">
                             Publications
                          </a></li>
                         <li><a href="http://chrisstucchio.com/work.html">
                             Work
                          </a></li>
                <li><a href="http://github.com/stucchio">Code</a></li>
                <li><a href="http://chrisstucchio.com/blog/index.html">Blog</a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li><a href="http://chrisstucchio.com/archives.html"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<div class="container">
    <div class="row">
        <div class="col-lg-12">

    <section id="content">
        <article>
            <header class="page-header">

                <h1>
                    <a href="http://chrisstucchio.com/blog/2013/hadoop_hatred.html"
                       rel="bookmark"
                       title="Permalink to Don't use Hadoop - your data isn't that big">
                       Don't use Hadoop - your data isn't that big
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
  <footer class="post-info">
    <span class="published">
        <time datetime="2013-09-16T11:30:00"> Mon 16 September 2013</time>
    </span>



	<a href="http://chrisstucchio.com/tag/big-data.html">big data</a>
        /
	<a href="http://chrisstucchio.com/tag/buzzwords.html">buzzwords</a>
        /
	<a href="http://chrisstucchio.com/tag/hadoop.html">hadoop</a>
    


</footer>
<footer class="post-info">
<span>
    <div id="twitter_share">
      <a href="https://twitter.com/stucchio" class="twitter-follow-button" data-show-count="false" data-dnt="true">Follow @stucchio</a>
    </div>
    <div id="facebook_like">
      <div class="fb-like" data-send="true" data-width="450" data-show-faces="true"></div>
    </div>
<div id="fb-root"></div>
<div><g:plusone size="medium" annotation="inline"></g:plusone></div>
</span>

<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));
</script>

<script type="text/javascript">
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script>
<script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
<script type="text/javascript">
  window.twttr.ready(function () {
  window.twttr.widgets.createShareButton(
  document.location.href,
  document.getElementById('twitter_share'),
  function (el) {},
  {
  size: 'small',
  via: 'stucchio'
  }
  )});
</script>
</footer>
                    </div>
                </div>
                <p>"So, how much experience do you have with Big Data and Hadoop?" they asked me. I told them that I use Hadoop all the time, but rarely for jobs larger than a few TB. I'm basically a big data neophite - I know the concepts, I've written code, but never at scale.</p>
<p>The next question they asked me. "Could you use Hadoop to do a simple group by and sum?" Of course I could, and I just told them I needed to see an example of the file format.</p>
<p>They handed me a flash drive with all 600MB of their data on it (not a sample, everything). For reasons I can't understand, they were unhappy when my solution involved <code>pandas.read_csv</code> rather than Hadoop.</p>
<p>Hadoop is limiting. Hadoop allows you to run one general computation, which I'll illustrate in pseudocode:</p>
<p>Scala-ish pseudocode:</p>
<div class="highlight"><pre><span class="n">collection</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">F</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="p">).</span><span class="n">groupBy</span><span class="p">(</span> <span class="n">_</span><span class="p">.</span><span class="n">_1</span> <span class="p">).</span><span class="n">map</span><span class="p">(</span> <span class="n">_</span><span class="p">.</span><span class="n">reduce</span><span class="p">(</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">G</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>


<p>SQL-ish pseudocode:</p>
<div class="highlight"><pre><span class="n">SELECT</span> <span class="n">G</span><span class="p">(...)</span> <span class="n">FROM</span> <span class="n">table</span> <span class="n">GROUP</span> <span class="n">BY</span> <span class="n">F</span><span class="p">(...)</span>
</pre></div>


<p>Or, as I <a href="../2011/mapreduce_explained.html">explained</a> a couple of years ago:</p>
<blockquote>
<p>Goal: count the number of books in the library.</p>
<p>Map: You count up the odd-numbered shelves, I count up the even numbered shelves. (The more people we get, the faster this part goes. )</p>
<p>Reduce: We all get together and add up our individual counts.</p>
</blockquote>
<p>The <em>only</em> thing you are permitted to touch is <code>F(k,v)</code> and <code>G(k,v)</code>, except of course for performance optimizations (usually not the fun kind!) at intermediate steps. Everything else is fixed.</p>
<p>It forces you to write every computation in terms of a map, a group by, and an aggregate, or perhaps a sequence of such computations. Running computations in this manner is a straightjacket, and many calculations are better suited to some other model. The only reason to put on this straightjacket is that by doing so, you can scale up to extremely large data sets. Most likely your data is orders of magnitude smaller.</p>
<p>But because "Hadoop" and "Big Data" are buzzwords, half the world wants to wear this straightjacket even if they don't need to.</p>
<h2>But my data is hundreds of megabytes! Excel won't load it.</h2>
<p>Too big for Excel is not "Big Data". There are excellent tools out there - my favorite is <a href="http://pandas.pydata.org/">Pandas</a> which is built on top of <a href="http://www.numpy.org/">Numpy</a>. You can load hundreds of megabytes into memory in an efficient vectorized format. On my 3 year old laptop, it takes numpy the blink of an eye to multiply 100,000,000 floating point numbers together. Matlab and R are also excellent tools.</p>
<p>Hundreds of megabytes is also typically amenable to a simple python script that reads your file line by line, processes it, and writes to another file.</p>
<h3>But my data is 10 gigabytes!</h3>
<p>I just bought a new laptop. The <a href="http://www.amazon.com/gp/product/B0076W9Q5A/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B0076W9Q5A&amp;linkCode=as2&amp;tag=christuc-20">16GB of ram</a> I put in cost me $141.98 and the 256gb SSD was $200 extra (preinstalled by Lenovo). Additionally, if you load a 10 GB csv file into <a href="http://pandas.pydata.org/">Pandas</a>, it will often be considerably smaller in memory - the result of storing the numerical string "17284932583" as a 4 or 8 byte integer, or storing "284572452.2435723" as an 8 byte double.</p>
<p>Worst case, you might actually have to not load everything into ram simultaneously.</p>
<h3>But my data is 100GB/500GB/1TB!</h3>
<p>A <a href="http://www.amazon.com/gp/product/B005T3GRN2/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B005T3GRN2&amp;linkCode=as2&amp;tag=christuc-20">2 terabyte hard drive</a> costs $94.99, <a href="http://www.amazon.com/gp/product/B005T3GRN2/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B005T3GRN2&amp;linkCode=as2&amp;tag=christuc-20">4 terabytes</a> is $169.99. Buy one and stick it in a desktop computer or server. Then install <a href="http://www.postgresql.org/">Postgres</a> on it.</p>
<h2>Hadoop &lt;&lt; SQL, Python Scripts</h2>
<p>In terms of expressing your computations, Hadoop is strictly inferior to SQL. There is no computation you can write in Hadoop which you cannot write more easily in either SQL, or with a simple Python script that scans your files.</p>
<p>SQL is a straightforward query language with minimal leakage of abstractions, commonly used by business analysts as well as programmers. Queries in SQL are generally pretty simple. They are also usually very fast - if your database is properly indexed, multi-second queries will be uncommon.</p>
<p>Hadoop does not have any conception of indexing. Hadoop has only full table scans. Hadoop is full of leaky abstractions - at my last job I spent more time fighting with <a href="/blog/2013/gc_overhead_limit.html">java memory errors</a>, file fragmentation and cluster contention than I spent actually worrying about the mostly straightforward analysis I wanted to perform.</p>
<p>If your data is not structured like a SQL table (e.g., plain text, json blobs, binary blobs), it's generally speaking straightforward to write a small python or ruby script to process each row of your data. Store it in files, process each file, and move on. Under circumstances where SQL is a poor fit, Hadoop will be less annoying from a programming perspective. But it still provides no advantage over simply writing a Python script to read your data, process it, and dump it to disk.</p>
<p>In addition to being more difficult to code for, Hadoop will also nearly always be slower than the simpler alternatives. SQL queries can be made very fast by the judicious use of indexes - to compute a join, PostgreSQL will simply look at an index (if present) and look up the exact key that is needed. Hadoop requires a full table scan, followed by re-sorting the entire table. The sorting can be made faster by sharding across multiple machines, but on the other hand you are still required to stream data across multiple machines. In the case of processing binary blobs, Hadoop will require repeated trips to the namenode in order to find and process data. A simple python script will require repeated trips to the filesystem.</p>
<h2>But my data is more than 5TB!</h2>
<p>Your life now sucks - you are stuck with Hadoop. You don't have many other choices (big servers with many hard drives might still be in play), and most of your other choices are considerably more expensive.</p>
<p>The only benefit to using Hadoop is scaling. If you have a single table containing many terabytes of data, Hadoop might be a good option for running full table scans on it. If you don't have such a table, avoid Hadoop like the plague. It isn't worth the hassle and you'll get results with less effort and in less time if you stick to traditional methods.</p>
<h2>P.S. The Sales Pitch</h2>
<p>I'm building a <a href="http://www.bayesianwitch.com/">startup</a> aiming to provide data analysis (big and small) and realtime recommendations and optimization to publishers and e-commerce sites. Go check it out.</p>
<h2>P.P.S. Hadoop is a fine tool</h2>
<p>I don't intend to hate on Hadoop. I use Hadoop regularly for jobs I probably couldn't easily handle with other tools. (Tip: I recommend using <a href="https://github.com/twitter/scalding">Scalding</a> rather than Hive or Pig. Scalding lets you use Scala, which is a decent programming language, and makes it easy to write chained Hadoop jobs without hiding the fact that it really is mapreduce on the bottom.) Hadoop is a fine tool, it makes certain tradeoffs to target certain specific use cases. The only point I'm pushing here is to think carefully rather than just running <strong>Hadoop</strong> on <strong>The Cloud</strong>  in order to handle your 500mb of <strong>Big Data</strong> at an <strong>Enterprise Scale</strong>.</p>
<div id="20b31ba3-7082-4740-a2e0-9ab716540e02"></div>

<script type="text/javascript" id="bandit-javascript">
        (function(){window.BayesianWitch=window.BayesianWitch||{};window.BayesianWitch.variations=window.BayesianWitch.variations||{};window.BayesianWitch.variationNotifySuccess=window.BayesianWitch.variationNotifySuccess||{};window.BayesianWitch.variationGetSuccessData=window.BayesianWitch.variationGetSuccessData||{};var logCustom=function(data){if(window.BayesianWitch.customEventsFired)window.BayesianWitch.logCustom(data);else{window.BayesianWitch.customEvents=window.BayesianWitch.customEvents||[];window.BayesianWitch.customEvents.push(data)}};
var bandit={"bandit":{"uuid":"20b31ba3-7082-4740-a2e0-9ab716540e02","tag":"hadoop_linkout","site":{"client":{"id":4,"uuid":"3f68e356-e7a8-4714-807f-d6ce31b659ff","name":"f3810710421dd621f6c9a28c7fe6ba"},"domain":"chrisstucchio.com","uuid":"cdfdf2e8-8937-4fa8-9a5b-7595f8b3487f"},"createdAt":1392556699886,"kind":"content_snippet"},"variations":[{"tag":"version1","isActive":true,"contentAndType":{"content":"<p>If you need help getting started with Hadoop, O&#39;Reilly has a <a href=\"http://www.amazon.com/gp/product/1449311520/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1449311520&amp;linkCode=as2&amp;tag=christuc-20\">decent</a> (albeit slightly outdated) intro that will help you, only <a href=\"http://www.amazon.com/gp/product/1449311520/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1449311520&amp;linkCode=as2&amp;tag=christuc-20\">$32 on amazon</a>.</p>\r\n","content_type":"text/html"},"uuid":"df5dc133-c4b7-4015-95d3-e7024dccb764"},{"tag":"version2","isActive":true,"contentAndType":{"content":"<p>A good introductory book for Hadoop is O&#39;Reilly&#39;s <a href=\"http://www.amazon.com/gp/product/1449311520/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1449311520&amp;linkCode=as2&amp;tag=christuc-20\">Hadoop: The Definitive Guide</a>. Only $32 on Amazon.</p>\r\n","content_type":"text/html"},"uuid":"a5ab6f19-fa27-42ff-8bd2-a2d167ba1d57"}],"kind":"content_snippet"};var fallbackDelay=500;var maxAge=2592000;var divToInsert=document.getElementById(bandit.bandit.uuid);var banditDisplayed=false;var alreadySeenVersion=null;var cookieName="bwsn_"+bandit.bandit.uuid;var cookiePosition=document.cookie.indexOf(cookieName+"\x3d");if(cookiePosition>=0)alreadySeenVersion=document.cookie.substring(cookiePosition+cookieName.length+1,cookiePosition+cookieName.length+1+36);var displayBandit=function(displayVariation){if(banditDisplayed)return false;
divToInsert.innerHTML=displayVariation.contentAndType.content;divToInsert.setAttribute("bayesianwitch_bd_var",displayVariation.uuid);divToInsert.setAttribute("bayesianwitch_bd_suc","true");logCustom({"bd_var":displayVariation.uuid});window.BayesianWitch.variationNotifySuccess[bandit.bandit.uuid]=function(){logCustom({"bd_var":displayVariation.uuid,"bd_suc":true})};window.BayesianWitch.variationGetSuccessData[bandit.bandit.uuid]=function(){return{"bd_var":displayVariation.uuid,"bd_suc":true}};banditDisplayed=
true;document.cookie=cookieName+"\x3d"+displayVariation.uuid+"; Max-Age\x3d"+maxAge+";";return true};var callbackName="bandit_display_"+bandit.bandit.uuid.replace(new RegExp("-","g"),"_");var fullCallbackName="window.BayesianWitch."+callbackName;window.BayesianWitch[callbackName]=displayBandit;var fallbackDisplayBandit=function(){if(banditDisplayed)return false;var displayVariation=null;if(alreadySeenVersion)for(var i=0;i<bandit.variations;i++){if(bandit.variations[i].uuid==alreadySeenVersion)displayVariation=
bandit.variations[i]}else displayVariation=bandit.variations[bandit.variations.length*Math.random()<<0];displayBandit(displayVariation);logCustom({"bd_var":bandit.bandit.uuid,"timeout":fallbackDelay})};window.BayesianWitch.variations[bandit.bandit.uuid]=displayBandit;window.setTimeout(fallbackDisplayBandit,fallbackDelay);var callback=document.createElement("script");callback.setAttribute("type","application/javascript");if(alreadySeenVersion)callback.setAttribute("src","http://recommend.bayesianwitch.com/bandit_rec/"+
bandit.bandit.uuid+"?version\x3d"+alreadySeenVersion+"\x26jsonpfunc\x3d"+fullCallbackName);else callback.setAttribute("src","http://recommend.bayesianwitch.com/bandit_rec/"+bandit.bandit.uuid+"?jsonpfunc\x3d"+fullCallbackName);document.body.appendChild(callback)})();
      </script>

<p><em>This article is also available <a href="http://habrahabr.ru/post/194434/">translated into Russian</a>.</em></p>
            </div>
            <!-- /.entry-content -->
    <hr />
    <section class="comments" id="comments">
        <h2>Comments</h2>
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'chrisstucchiosblog'; // required: replace example with your forum shortname
            var disqus_identifier = 'hadoop_hatred';
            var disqus_url = 'http://chrisstucchio.com/blog/2013/hadoop_hatred.html';
            var disqus_config = function () {
                this.language = "en";
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2014 Chris Stucchio
            &middot; Powered by <a href="https://github.com/DandyDev/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="//code.jquery.com/jquery.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="http://chrisstucchio.com/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="http://chrisstucchio.com/theme/js/respond.min.js"></script>

    <script type="text/javascript">
        var disqus_shortname = 'chrisstucchiosblog';
	var disqus_identifier = "Don't use Hadoop - your data isn't that big-2013-09-16 11:30:00";
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-30538320-1']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();

    </script>
<script type="text/javascript">var _paq = _paq || [];
(function(){
   var u=(("https:" == document.location.protocol) ? "https://embed.bayesianwitch.com" : "http://embed.bayesianwitch.com");
   _paq.push(['setSiteId', "cdfdf2e8-8937-4fa8-9a5b-7595f8b3487f"]);
   _paq.push(['setTrackerUrl', "http://r.bayesianwitch.com"]);
   _paq.push(['enableLinkTracking']);
   _paq.push(['setCookieDomain', '*.chrisstucchio.com']);
   _paq.push(['setDomains', '*.chrisstucchio.com']);
   _paq.push(['trackPageView']);
   var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
   g.type='text/javascript'; g.defer=true; g.async=true; g.src=u+'/bayesianwitch.min.js';
   s.parentNode.insertBefore(g,s);

   window.BayesianWitch = window.BayesianWitch || {};
   window.BayesianWitch.customEvents = window.BayesianWitch.customEvents || [];
   window.logCustom = function(data) { window.BayesianWitch.customEvents.push(data); };
})();
</script>
</body>
</html>