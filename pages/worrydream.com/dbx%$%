<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <base target="_top">

    <title>References for "The Future of Programming"</title>
    <link href='http://fonts.googleapis.com/css?family=Asap:400,400italic,700,700italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="style.css" type="text/css">

</head>

<body>


<h1>References for "The Future of Programming"</h1>
<h4><a class="selflink" href="http://worrydream.com">Bret Victor</a> / July 30, 2013</h4>

<div class="intro">

<p>I gave a talk at the DBX conference called <b><a href="http://vimeo.com/71278954">The Future of Programming</a></b>.  Below are links and quotes from some primary sources I used, as well as links to wikipedia and elsewhere where you can learn more.</p>

<iframe src="http://player.vimeo.com/video/71278954" width="470" height="264" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>

</div>

<h2>Introduction</h2>

<div class="slide clear"><img src="slides/slide.002.png" width="420" height="315"></div>

<p>Much of the overall message and style of the talk was inspired by <a href="http://en.wikipedia.org/wiki/Alan_Kay">Alan Kay</a>.</p>

<p>For more talks with a similar message, I highly recommend:</p>
<ul>
<li><a href="http://www.tele-task.de/archive/lecture/overview/5819/">Alan Kay -- Programming and Scaling</a> (video)</li>
<li><a href="http://www.infoq.com/presentations/We-Really-Dont-Know-How-To-Compute">Gerry Sussman -- We Really Don't Know How To Compute!</a> (video)</li>
</ul>

<p>For a broader overview of some of the systems and ideas in this talk, see:</p>
<ul>
<li><a href="http://archive.org/details/AlanKeyD1987">Alan Kay -- Doing With Images Makes Symbols, part 1</a> and <a href="http://archive.org/details/AlanKeyD1987_2">part 2</a> (video)</li>
</ul>


<div class="slide clear"><img src="slides/slide.004.png" width="420" height="315"></div>

<p><b>Moore's law</b></p>
<ul>
<li><a href="http://download.intel.com/museum/Moores_Law/Articles-Press_Releases/Gordon_Moore_1965_Article.pdf">Gordon Moore (1965) -- Cramming more components onto integrated circuits</a></li>
<li><a href="http://en.wikipedia.org/wiki/Moore's_law">wikipedia</a></li>
</ul>


<div class="slide clear"><img src="slides/slide.005.png" width="420" height="315"></div>

<p><b>IBM 650</b></p>
<ul>
<li><a href="http://www.columbia.edu/cu/computinghistory/650.html">Columbia University Computing History -- IBM 650 and the SOAP assembler</a></li>
<li><a href="http://bitsavers.informatik.uni-stuttgart.de/pdf/ibm/650/">Bitsavers -- Manuals for the IBM 650, its SOAP and Fortran, etc.</a></li>
<li><a href="http://en.wikipedia.org/wiki/IBM_650">wikipedia</a></li>
</ul>

<div class="slide clear"><div class="pair"><img src="slides/slide.006.png" width="420" height="315"><img src="slides/slide.007.png" width="420" height="315"></div></div>

<p><b>Reactions to SOAP and Fortran</b><br>
<a class="indented" href="http://worrydream.com/refs/Hamming-TheArtOfDoingScienceAndEngineering.pdf">Richard Hamming -- The Art of Doing Science and Engineering, p25</a> (pdf book)</p>

<p class="quote">In the beginning we programmed in absolute binary... Finally, a Symbolic Assembly Program was devised -- after more years than you are apt to believe during which most programmers continued their heroic absolute binary programming. At the time [the assembler] first appeared I would guess about 1% of the older programmers were interested in it -- using [assembly] was "sissy stuff", and a real programmer would not stoop to wasting machine capacity to do the assembly.</p>

<p class="quote">Yes! Programmers wanted no part of it, though when pressed they had to admit their old methods used more machine time in locating and fixing up errors than the [assembler] ever used. One of the main complaints was when using a symbolic system you do not know where anything was in storage -- though in the early days we supplied a mapping of symbolic to actual storage, and believe it or not they later lovingly pored over such sheets rather than realize they did not need to know that information if they stuck to operating within the system -- no! When correcting errors they preferred to do it in absolute binary.</p>

<p class="quote">FORTRAN was proposed by Backus and friends, and again was opposed by almost all programmers. First, it was said it could not be done. Second, if it could be done, it would be too wasteful of machine time and capacity. Third, even if it did work, no respectable programmer would use it -- it was only for sissies!</p>


<p style="margin-top:30px;"><b>John von Neumann's reaction to assembly language and Fortran</b><br>
<a class="indented" href="http://www.columbia.edu/cu/computinghistory/index.html">John A.N. Lee, Virginia Polytechnical Institute</a></p>

<p class="quote">John von Neumann, when he first heard about FORTRAN in 1954, was unimpressed and asked "why would you want more than machine language?" One of von Neumann's students at Princeton recalled that graduate students were being used to hand assemble programs into binary for their early machine. This student took time out to build an assembler, but when von Neumann found out about it he was very angry, saying that it was a waste of a valuable scientific computing instrument to use it to do clerical work.</p>



<h2>coding -&gt; direct manipulation of data</h2>

<div class="slide clear"><img src="slides/slide.013.png" width="420" height="315"></div>

<p><b>Sketchpad</b> (Ivan Sutherland)</p>
<ul>
<li><a href="http://archive.org/details/AlanKeyD1987?start=249.5">video</a> (from Alan Kay's talk "Doing With Images Makes Symbols")</li>
<li><a href="http://worrydream.com/refs/Sutherland-Sketchpad.pdf">thesis</a></li>
<li><a href="http://en.wikipedia.org/wiki/Sketchpad">wikipedia</a></li>
</ul>

<h2>procedures -&gt; goals and constraints</h2>

<div class="slide clear"><img src="slides/slide.017.png" width="420" height="315"></div>

<p><b>PLANNER</b> (Carl Hewitt)</p>
<ul>
<li><a href="http://arxiv.org/pdf/0904.3036v25.pdf">Carl Hewitt -- Middle History of Logic Programming</a></li>
<li><em>In summary, Prolog was basically a subset of Planner that restricted programs to clausal form using backward chaining.</em>
<li style="padding-top:8px;"><a href="http://en.wikipedia.org/wiki/Planner_(programming_language)">wikipedia</a></li>
</ul>

<p><b>Prolog</b> (Alain Colmerauer, et al)</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Prolog">wikipedia</a></li>
</ul>


<div class="slide clear"><img src="slides/slide.019.png" width="420" height="315"></div>

<p><b>SNOBOL</b> (Ralph Griswold, et al)</p>
<ul>
<li><a href="http://worrydream.com/refs/Griswold-TheSnobolProgrammingLanguage.pdf">Ralph Griswold, et al -- The SNOBOL 4 Programming Lanaguage</a> (pdf book)</li>
<li><a href="http://en.wikipedia.org/wiki/Snobol">wikipedia</a></li>
</ul>

<p><b>regular expressions</b> (Ken Thompson)</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Regular_expression#History">wikipedia</a> (history)</li>
</ul>


<div class="slide clear"><img src="slides/slide.020.png" width="420" height="315"></div>

<p><b>ARPANET</b></p>
<ul>
<li><a href="http://worrydream.com/refs/Licklider-IntergalacticNetwork.pdf">J.C.R. Licklider -- 1963 memo about the "Intergalactic Computer Network"</a></li>
<li><a href="http://www.ibiblio.org/pioneers/licklider.html">J.C.R. Licklider bio</a></li>
<li><a href="http://en.wikipedia.org/wiki/ARPANET">wikipedia</a></li>
</ul>

<p><b>Communicating with aliens</b></p>
<ul>
<li>The interpretation I gave is due to Alan Kay (most clearly in personal communication, but see the following segments):</li>
<li><a href="http://www.youtube.com/watch?v=BbwOPzxuJ0s&t=35m35s">Alan Kay -- SCIx Keynote</a> (see 35:35 - 36:50)</li>
<li><a href="http://www.tele-task.de/archive/lecture/overview/5819/">Alan Kay -- Programming and Scaling</a> (see 15:28 - 22:20)</li>
</ul>

<p><b>see also</b></p>
<ul>
<li><a href="http://worrydream.com/refs/Licklider%20-%20Man-Computer%20Symbiosis.pdf">J.C.R. Licklider (1960) -- Man-Computer Symbiosis</a> (see "computer instruction through specification of goals")</li>
</ul>


<h2>text dump -&gt; spatial representations</h2>

<div class="slide clear"><img src="slides/slide.024.png" width="420" height="315"></div>

<p><b>NLS</b> (Doug Engelbart, SRI)</p>
<ul>
<li><a href="http://www.dougengelbart.org/firsts/dougs-1968-demo.html">videos</a></li>
<li><a href="http://en.wikipedia.org/wiki/NLS_(computer_system)">wikipedia</a></li>
</ul>

<div class="slide clear"><img src="slides/slide.026.png" width="420" height="315"></div>

<p><b>GRAIL</b> (T.O. Ellis et al, RAND Corporation)</p>
<ul>
<li><a href="http://archive.org/details/AlanKeyD1987?start=1439.5">video</a> (from Alan Kay's talk "Doing With Images Makes Symbols")</li>
<li><a href="http://en.wikipedia.org/wiki/RAND_Tablet">wikipedia</a> (stub)</li>
</ul>


<div class="slide clear"><img src="slides/slide.027.png" width="420" height="315"></div>

<p><b>Smalltalk</b> (Alan Kay, Xerox PARC)</p>
<ul>
<li><a href="http://worrydream.com/EarlyHistoryOfSmalltalk/">Alan Kay -- The Early History of Smalltalk</a></li>
<li><a href="http://en.wikipedia.org/wiki/Smalltalk">wikipedia</a></li>
</ul>


<div class="slide clear"><img src="slides/slide.028.png" width="420" height="315"></div>

<p><b>PLATO</b> (Don Bitzer, University of Illinois)</p>
<ul>
<li><a href="http://platohistory.org/">PLATO History</a> (blog)</li>
<li><a href="http://bitsavers.informatik.uni-stuttgart.de/pdf/univOfIllinoisUrbana/plato/">manuals</a> (bitsavers)</li>
<li><a href="http://en.wikipedia.org/wiki/PLATO_(computer_system)">wikipedia</a></li>
</ul>



<h2>sequential -&gt; concurrent</h2>

<div class="slide clear"><img src="slides/slide.030.png" width="420" height="315"></div>

<p><b>von Neumann computer architecture</b></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Von_Neumann_architecture">wikipedia</a></li>
</ul>

<p><b>von Neumann bottleneck</b><br>
<a class="indented" href="http://worrydream.com/refs/Backus-CanProgrammingBeLiberated.pdf">John Backus (1978) -- Can Programming Be Liberated from the von Neumann Style?</a></p>

<p class="quote">Surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von Neumann bottleneck. Not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. Thus programming is basically planning and detailing the enormous traffic of words through the von Neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.</p>



<div class="slide clear"><img src="slides/slide.031.png" width="420" height="315"></div>

<p><b>semiconductor integrated circuit</b></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Integrated_circuit">wikipedia</a> (history)</li>
</ul>

<p><b>Intel 4004 microprocessor</b></p>
<ul>
<li><a href="http://www.4004.com">die photo</a></li>
<li><a href="http://en.wikipedia.org/wiki/Intel_4004">wikipedia</a></li>
</ul>

<p><b>semiconductor memory</b></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Dynamic_random-access_memory#History">wikipedia</a> (history)</li>
</ul>


<div class="slide clear"><img src="slides/slide.032.png" width="420" height="315"></div>

<p><b>massively parallel processor array</b></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Massively_parallel_processor_array">wikipedia</a></li>
</ul>

<p><b>see also</b></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA (1985)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Connection_Machine">Connection Machine (1983)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Transputer">Transputer (1984)</a></li>
<li><a href="http://www.greenarraychips.com">GreenArrays (2009)</a></li>
</ul>


<div class="slide clear"><img src="slides/slide.034.png" width="420" height="315"></div>

<p><b>Actor model</b> (Carl Hewitt)</p>
<ul>
<li><a href="http://worrydream.com/refs/Hewitt-ActorModel.pdf">Carl Hewitt (1973) -- A Universal Modular ACTOR Formalism for Artificial Intelligence</a></li>
<li><a href="http://en.wikipedia.org/wiki/Actor_model">wikipedia</a></li>
</ul>

<p><b>referenced in passing</b></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Kahn_process_networks">Gilles Khan -- Kahn process networks</a></li>
<li><a href="http://en.wikipedia.org/wiki/Communicating_sequential_processes">Tony Hoare -- Communicating Sequential Processes (CSP)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Calculus_of_communicating_systems">Robin Milner -- Calculus of Communicating Systems (CCS)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Pi-calculus">Robin Milner -- pi-calculus</a></li>
<li><a href="http://en.wikipedia.org/wiki/Erlang_(programming_language)">Joe Armstrong, et al -- Erlang</a> ("the Swedish telephone company")</li>
</ul>


<h2>Closing</h2>

<p><b>"We don't know what programming is."</b></p>

<p><a class="indented" href="http://www.infoq.com/presentations/We-Really-Dont-Know-How-To-Compute">Gerry Sussman -- We Really Don't Know How To Compute!</a> (video)</p>

<p class="quote">[intro] I think we're in real trouble.  I think we haven't the foggiest idea how to compute real well...  I think that most of the things we've been talking about, even here [at this conference], are obsolete.</p>

<p class="quote">[40:30] I'm only pushing this idea, not because I think it's the right answer. I'm trying to twist us, so we say, "This is a different way to think." We have to think fifty-two different ways to fix this problem. I don't know how to make a machine that builds a person out of a cell. But I think the problem is that we've been stuck for too long diddling with our details. We've been sitting here worrying about our type system, when we should be worrying about how to get flexible machines and flexible programming.</p>

<p class="quote">[1:01:30] We have to throw away our current ways of thinking if we ever expect to solve these problems.</p>


<p><span class="indented">See also <a href="http://www.youtube.com/watch?v=oKg1hTOQXoY">Alan Kay -- The Computer Revolution Hasn't Happened Yet</a> (video)</span></p>


<p><b>"The most dangerous thought you can have as a creative person is to think you know what you're doing."</b></p>

<p><a class="indented" href="http://worrydream.com/refs/Hamming-TheArtOfDoingScienceAndEngineering.pdf">Richard Hamming -- The Art of Doing Science and Engineering, p5</a> (pdf book)</p>

<p class="quote">In science if you know what you are doing you should not be doing it.
<br>In engineering if you do not know what you are doing you should not be doing it.
<br>Of course, you seldom, if ever, see either pure state.</p>

<p><a class="indented" href="http://longnow.org/essays/richard-feynman-connection-machine">Danny Hillis -- Richard Feynman and The Connection Machine</a></p>

<p class="quote">In retrospect I realize that in almost everything that we [Hillis and Feynman] worked on together, we were both amateurs. In digital physics, neural networks, even parallel computing, we never really knew what we were doing. But the things that we studied were so new that no one else knew exactly what they were doing either. It was amateurs who made the progress.</p>


<h2>"Why did all these ideas happen during this particular time period?"</h2>

<p>There may be a number of reasons.</p>

<p>The story I told in the talk -- "they didn't know what they were doing, so they tried everything" -- was essentially that programming at the time was in the "pre-<a href="https://en.wikipedia.org/wiki/Paradigm">paradigm</a> phase", as defined by Thomas Kuhn in <a href="http://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions">The Structure of Scientific Revolutions</a>.  This is the period of time before researchers reach consensus on what problems they're actually trying to solve.  The establishment of distinct <a href="https://en.wikipedia.org/wiki/Programming_paradigm">programming paradigms</a> (e.g., functional, logic, etc.) led into Kuhn's "normal science" phase (or as Sussman put it, "diddling with details") where the foundations of the subject tend to be taken for granted.</p>

<p>But there's another story, which has to do with funding models.  Much fundamental research at the time, including Engelbart's NLS and the Internet, was funded by <a href="http://en.wikipedia.org/wiki/DARPA">ARPA</a>, an agency of the US Defense Department which had been given significant resources due to the cold war.</p>

<p><a class="indented" href="http://worrydream.com/refs/FoundingOfTheAILab.pdf">Stefanie Chiou, et al -- The Founding of the MIT AI Lab</a></p>

<p class="quote">ARPA ushered in an era of abundant funding for university projects, offering far more in terms of funding than any other research funds at the time. Where institutions such as the National Science Foundation and the Three Services Program provided funding to research programs at the level of tens of thousands of dollars, ARPA was willing to throw millions into the creation and support of promising research efforts.</p>

<p>Part of what made ARPA funding so successful was that its directors (such as <a href="http://en.wikipedia.org/wiki/JCR_Licklider">J.C.R. Licklider</a> and <a href="http://en.wikipedia.org/wiki/Robert_Taylor_(computer_scientist)">Bob Taylor</a>) were free to aggressively seek out and fund the most promising individuals with "no strings attached".</p>

<p><a class="indented" href="http://worrydream.com/refs/FoundingOfTheAILab.pdf">Ibid.</a></p>

<p class="quote">The funding model used within ARPA at the time was that of giving large chunks of money to individual laboratories to be divided up at the discretion of the laboratory director.</p>

<p>This situation changed around 1973, when ARPA became DARPA.  (The D is for Defense.)</p>

<p><a class="indented" href="http://en.wikipedia.org/wiki/DARPA">wikipedia</a></p>

<p class="quote">The Mansfield Amendment of 1973 expressly limited appropriations for defense
research (through ARPA/DARPA) to projects with <i>direct military application</i>.
Some contend that the amendment devastated American science, since
ARPA/DARPA was a major funding source for basic science projects of the
time; the National Science Foundation never made up the difference as
expected.</p>

<p class="quote">The resulting "brain drain" is also credited with boosting the development
of the fledgling personal computer industry. Many young computer scientists
fled from the universities to startups and private research labs like Xerox
PARC.</p>

<p>One way of interpreting this is that the Mansfield Amendment killed research, but "induced labor" on an industry.  The industrial mindset -- short-term, results-driven, immediately-applicable -- is generally hostile to long-term, exploratory, foundational research.  (The canonical counterexamples, <a href="http://en.wikipedia.org/wiki/Bell_Labs">Bell Labs</a> and <a href="http://en.wikipedia.org/wiki/PARC_(company)">Xerox PARC</a>, were anomalies for various reasons.  See <a href="http://www.amazon.com/dp/0143122797">The Idea Factory</a> and <a href="http://www.amazon.com/dp/0887309895">Dealers of Lightning</a>, respectively.)</p>

<p>The <a href="http://en.wikipedia.org/wiki/National_Science_Foundation">National Science Foundation</a> continued to exist as a basic-science funding agency.  But unlike ARPA, the NSF funds <i>projects, not people</i>, and project proposals must be accepted by a peer review board.  Any sufficiently-revolutionary project, especially at the early stages, will sound too crazy for a board to accept.  Worse, requiring a detailed project proposal means that the NSF simply can't fund truly exploratory research, where the goal is not to solve a problem, but to discover and understand the problem in the first place.</p>

<p>A third story to explain why so many ideas happened during this time period was that everyone was on drugs.  See <a href="http://www.amazon.com/dp/0143036769">What the Dormouse Said</a>.</p>


<h2>A clarification about "not knowing what you're doing"</h2>

<div class="xoutro">

<p><b>"The most dangerous thought you can have as a creative person is to think you know what you're doing."</b></p>

<p>It's possible to misinterpret what I'm saying here.  When I talk about not knowing what you're doing, I'm arguing against "expertise", a feeling of mastery that traps you in a particular way of thinking.</p>

<p>But I want to be clear -- <i>I am not advocating ignorance.</i>  Instead, I'm suggesting a kind of informed skepticism, a kind of humility.</p>

<p>Ignorance is remaining willfully unaware of the existing base of knowledge in a field, proudly jumping in and stumbling around.  This approach is fashionable in certain hacker/maker circles today, and it's poison.</p>

<p>Knowledge is essential.  Past ideas are essential.  Knowledge and ideas that have coalesced into <i>theory</i> is one of the most beautiful creations of the human race.  Without Maxwell's equations, you can spend a lifetime fiddling with radio equipment and never invent radar.  Without dynamic programming, you can code for days and <a href="http://pindancing.blogspot.com/2009/09/sudoku-in-coders-at-work.html">not even build a sudoku solver</a>.
</p>

<p>It's good to learn how to do something.  It's better to learn many ways of doing something.  But it's best to learn all these ways as <i>suggestions or hints</i>.  Not <i>truth</i>.</p>

<p>Learn tools, and use tools, but don't <i>accept</i> tools.  Always distrust them; always be alert for alternative ways of thinking.  This is what I mean by avoiding the conviction that you "know what you're doing".</p>

<p class="separator">* * *</p>

<p>This point is perhaps best made by David Hestenes. Here, he's writing about mathematical tools for physics, but his observation applies identically to any sort of tool or way of thinking:</p>

<p><a class="indented" href="http://worrydream.com/refs/Hestenes-ReformingTheMathematicalLanguageOfPhysics.pdf">David Hestenes -- Reforming the Mathematical Language of Physics</a></p>

<p class="quote">Mathematics is taken for granted in the physics curriculum -- a body of immutable truths to be assimilated and applied. The profound influence of mathematics on our conceptions of the physical world is never analyzed. The possibility that mathematical tools used today were <b>invented to solve problems in the past and might not be well suited for current problems</b> is never considered...</p>

<p class="quote">One does not have to go very deeply into the history of physics to discover the profound influence of mathematical invention. Two famous examples will suffice to make the point: The invention of analytic geometry and calculus was essential to Newton’s creation of classical mechanics. The invention of tensor analysis was essential to Einstein’s creation of the General Theory of Relativity.</p>

<p class="quote">The point I wish to make by citing these two examples is that without essential mathematical concepts the two theories would have been literally inconceivable. <b>The mathematical modeling tools we employ at once extend and limit our ability to conceive the world.</b> Limitations of mathematics are evident in the fact that the analytic geometry that provides the foundation for classical mechanics is insufficient for General Relativity. This should alert one to the possibility of other conceptual limits in the mathematics used by physicists.</p>

<p>Lastly, here's some advice Alan Kay gave me (as I was going through a small personal crisis as a result of reading Jerome Bruner's "Toward a Theory of Instruction"):</p>

<p style="padding-left:20px;"><em>I think the trick with knowledge is to "acquire it, and forget all except the perfume" -- because it is noisy and sometimes drowns out one's own "brain voices". The perfume part is important because it will help find the knowledge again to help get to the destinations the inner urges pick.</em></p>

</div>

</body></html>
